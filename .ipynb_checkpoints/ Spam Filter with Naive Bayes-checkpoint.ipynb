{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Spam Filter with Naive Bayes\n",
    "\n",
    "In this project I am going to built a spam filter with the Naive Bayes algorithm, based in the Bayes theorem. We will use some messages provided by the UCI Machine Learning Repository to \"teach\" the computer how to classify this messages. This messages have been already classified as spam or not. This messages have been collected from:\n",
    "\n",
    "- Grumbletext web site -> A UK forum where users make public claims about SMS spam messages.\n",
    "- NYS SMS Corpus (NSC) -> Department of Computer Science at the National University of Singapore\n",
    "- Caroline Tag's PhD Thesis available at http://etheses.bham.ac.uk/253/1/Tagg09PhD.pdf\n",
    "\n",
    "You can download the dataset from the following link: https://archive.ics.uci.edu/ml/datasets/sms+spam+collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset\n",
    "\n",
    "First we are going to import the dataset and some python packages for data manipulation as pandas and numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "df = pd.read_csv(\"SMSSpamCollection\", sep='\\t', header=None, names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to explore the dataset and see how many rows and columns it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5567</td>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5568</td>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5569</td>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5570</td>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5571</td>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "Label    5572 non-null object\n",
      "SMS      5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label                     SMS\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: Label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x296b5598a48>"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.Label.value_counts())\n",
    "\n",
    "df.Label.value_counts().plot(kind=\"bar\", rot=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important information:\n",
    "\n",
    "The dataset is shaped by 5572 rows and 2 columns\n",
    "\n",
    "The are no null values.\n",
    "\n",
    "There are two types of labels for the messsages:\n",
    "- ham -> Non-spam messages\n",
    "- spam -> Spam messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messages percentages\n",
    "\n",
    "We are going to find what are the porcentages for spam and ham messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86.6% of messages are Non-Spam and 13.4% of the messages are Spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preapering the dataset\n",
    "\n",
    "Now we are going to split out dataset in two categories:\n",
    "- Training set -> This dataset will be used to \"train\" the computer to identify which messages are spam.\n",
    "- Test set -> We will use it to test how good the spam filter is.\n",
    "\n",
    "We are going to divide the dataset in the following way:\n",
    "- Training set will be made up of 80% of the dataset -> 4458 messages.\n",
    "- Test set will be made up of 20% of the dataset -> 1114 messages.\n",
    "\n",
    "With this changes, we expect an accurary grater than 80% at detecting spam messages. \n",
    "\n",
    "We will start randomizing the dataset that spam and non-spam messages are spread throughout the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rows and columns of the training set are:  (4458, 2)\n",
      "The rows and columns of the test set are:  (1114, 2)\n"
     ]
    }
   ],
   "source": [
    "randomized = df.sample(frac=1, random_state=1)\n",
    "\n",
    "training_len = int(round(len(df)*0.8,0))\n",
    "test_len = len(df)\n",
    "\n",
    "training_set = df[:4458].reset_index(drop=True)\n",
    "test_set = df[training_len:test_len].reset_index(drop=True)\n",
    "\n",
    "print(\"The rows and columns of the training set are: \", training_set.shape)\n",
    "print(\"The rows and columns of the test set are: \", test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to find the spam and non-spam percentages in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Training dataset---------\n",
      "Non-Spam percentage: 86.49618663077612\n",
      "Spam percentage: 13.503813369223867\n",
      "----------------------------------\n",
      "\n",
      "---------Test dataset---------\n",
      "Non-Spam percentage: 86.983842010772\n",
      "Spam percentage: 13.016157989228008\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spams_ham_list_train = training_set.Label.value_counts(normalize=True).values.tolist()\n",
    "ham_training = spams_ham_list_train[0]*100\n",
    "spam_training = spams_ham_list_train[1]*100\n",
    "\n",
    "print(\"---------Training dataset---------\")\n",
    "print(\"Non-Spam percentage: {}\\nSpam percentage: {}\".format(ham_training,spam_training))\n",
    "print(\"----------------------------------\\n\")\n",
    "\n",
    "spams_ham_list_test = test_set.Label.value_counts(normalize=True).values.tolist()\n",
    "ham_test = spams_ham_list_test[0]*100\n",
    "spam_test = spams_ham_list_test[1]*100\n",
    "\n",
    "print(\"---------Test dataset---------\")\n",
    "print(\"Non-Spam percentage: {}\\nSpam percentage: {}\".format(ham_test,spam_test))\n",
    "print(\"----------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the results that both datasets have very similar percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.869838\n",
       "spam    0.130162\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.Label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "We will create a function that will clean both datasets by removing punctuation and tranforming every word from the message to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>aight should i just plan to come up later toni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>die    i accidentally deleted e msg i suppose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>welcome to uk mobile date this msg is free giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>this is wishing you a great day  moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>thanks again for your reply today  when is ur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ham</td>\n",
       "      <td>sorry i flaked last night  shit s seriously go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ham</td>\n",
       "      <td>he said i look pretty wif long hair wat  but i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ham</td>\n",
       "      <td>ranjith cal drpd deeraj and deepak 5min hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>ham</td>\n",
       "      <td>cheers for callin babe sozi culdnt talkbut i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>ham</td>\n",
       "      <td>hey u still at the gym</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  aight should i just plan to come up later toni...\n",
       "1   ham  die    i accidentally deleted e msg i suppose ...\n",
       "2  spam  welcome to uk mobile date this msg is free giv...\n",
       "3   ham  this is wishing you a great day  moji told me ...\n",
       "4   ham  thanks again for your reply today  when is ur ...\n",
       "5   ham  sorry i flaked last night  shit s seriously go...\n",
       "6   ham  he said i look pretty wif long hair wat  but i...\n",
       "7   ham       ranjith cal drpd deeraj and deepak 5min hold\n",
       "8   ham  cheers for callin babe sozi culdnt talkbut i w...\n",
       "9   ham                            hey u still at the gym "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_dataset(dataset):\n",
    "    dataset[\"SMS\"] = dataset[\"SMS\"].str.replace('\\W', ' ')\n",
    "    dataset[\"SMS\"] = dataset[\"SMS\"].str.lower()\n",
    "    return dataset\n",
    "\n",
    "training_set = clean_dataset(training_set)\n",
    "test_set = clean_dataset(test_set)\n",
    "test_set.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the vocabulary\n",
    "\n",
    "Before we create the Naive Bayes algorithm,we need to create a set of unique words from all the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brains',\n",
       " 'mahal',\n",
       " 'claimcode',\n",
       " 'unconsciously',\n",
       " 'accordin',\n",
       " '310303',\n",
       " 'ed',\n",
       " 'bunkers',\n",
       " 'begins',\n",
       " 'ashley',\n",
       " '2channel',\n",
       " 'arent',\n",
       " 'big',\n",
       " '7',\n",
       " 'copies',\n",
       " 'supplies',\n",
       " 'dizzamn',\n",
       " 'luck',\n",
       " 'sigh',\n",
       " 'nuerologist',\n",
       " 'draws',\n",
       " '09099725823',\n",
       " 'naal',\n",
       " 'project',\n",
       " 'excited',\n",
       " 'troubleshooting',\n",
       " 'correction',\n",
       " 'er',\n",
       " 'yaxx',\n",
       " 'bbq',\n",
       " 'shadow',\n",
       " 'tming',\n",
       " 'endowed',\n",
       " 'hyde',\n",
       " '3mins',\n",
       " '5pm',\n",
       " 'conacted',\n",
       " 'intrude',\n",
       " 'po',\n",
       " 'census',\n",
       " 'doin',\n",
       " 'carryin',\n",
       " 'ee',\n",
       " 'caught',\n",
       " 'tendencies',\n",
       " 'extract',\n",
       " '30ish',\n",
       " 'renting',\n",
       " '10ppm',\n",
       " 'perspective',\n",
       " 'accessible',\n",
       " 'ntimate',\n",
       " 'se',\n",
       " 'gandhipuram',\n",
       " '1st4terms',\n",
       " 'pure',\n",
       " 'bang',\n",
       " 'childish',\n",
       " 'nigpun',\n",
       " 'sympathetic',\n",
       " 'means',\n",
       " 'lkpobox177hp51fl',\n",
       " 'receiving',\n",
       " 'pie',\n",
       " 'love',\n",
       " 'chiong',\n",
       " 'rent',\n",
       " 's3xy',\n",
       " 'rajini',\n",
       " 'saw',\n",
       " 'l8r',\n",
       " 'image',\n",
       " 'outstanding',\n",
       " 'theatre',\n",
       " 'frm',\n",
       " '49',\n",
       " 'twins',\n",
       " 'canal',\n",
       " 'potato',\n",
       " 'sometimes',\n",
       " 'shattered',\n",
       " 'newsletter',\n",
       " 'prin',\n",
       " 'jane',\n",
       " 'out',\n",
       " 'arts',\n",
       " 'ears',\n",
       " 'jordan',\n",
       " 'sts',\n",
       " 'bsn',\n",
       " 'wana',\n",
       " 'siva',\n",
       " 'moral',\n",
       " 'multis',\n",
       " 'phd',\n",
       " 'rto',\n",
       " 'believe',\n",
       " 'just',\n",
       " 'they',\n",
       " 'wow',\n",
       " 'cc100p',\n",
       " 'significant',\n",
       " 'plumbing',\n",
       " 'hop',\n",
       " 'entertain',\n",
       " 'dodda',\n",
       " 'emerging',\n",
       " '50p',\n",
       " 'white',\n",
       " 'minmobsmorelkpobox177hp51fl',\n",
       " 'jokin',\n",
       " 'hanumanji',\n",
       " 'glasgow',\n",
       " 'marley',\n",
       " 'paper',\n",
       " 'calculation',\n",
       " 'spain',\n",
       " 'tome',\n",
       " 'atlanta',\n",
       " 'frank',\n",
       " 'dint',\n",
       " 'housewives',\n",
       " 'nuclear',\n",
       " 'women',\n",
       " 'winds',\n",
       " 'd3wv',\n",
       " '26th',\n",
       " 'cancelled',\n",
       " 'visit',\n",
       " 'beth',\n",
       " 'peril',\n",
       " 'pataistha',\n",
       " 'loses',\n",
       " 'imp',\n",
       " 'em',\n",
       " 'recieve',\n",
       " '14tcr',\n",
       " 'longer',\n",
       " 'dedicate',\n",
       " 'contents',\n",
       " 'fondly',\n",
       " 'silence',\n",
       " 'minutes',\n",
       " 'oru',\n",
       " 'like',\n",
       " 'fortune',\n",
       " 'meat',\n",
       " 'angry',\n",
       " 'axis',\n",
       " 'bar',\n",
       " 'ummma',\n",
       " 'goodies',\n",
       " 'function',\n",
       " 'allo',\n",
       " '0906346330',\n",
       " 'imf',\n",
       " '1146',\n",
       " 'wonder',\n",
       " 'seemed',\n",
       " 'thnk',\n",
       " '08714712379',\n",
       " 'midnight',\n",
       " 'problematic',\n",
       " 'recharge',\n",
       " '09064012160',\n",
       " 'obviously',\n",
       " 'delicious',\n",
       " 'garage',\n",
       " 'june',\n",
       " 'juz',\n",
       " 'stressed',\n",
       " 'arun',\n",
       " 'shhhhh',\n",
       " 'recent',\n",
       " 'gent',\n",
       " 'thia',\n",
       " 'othrs',\n",
       " 'roast',\n",
       " 'doesdiscount',\n",
       " 'potter',\n",
       " 'formal',\n",
       " 'stayed',\n",
       " '08452810073',\n",
       " 'by',\n",
       " '08718730666',\n",
       " 'wise',\n",
       " 'comb',\n",
       " 'jaya',\n",
       " 'payment',\n",
       " 'bed',\n",
       " 'province',\n",
       " 'basketball',\n",
       " 'improved',\n",
       " 'gsoh',\n",
       " 'embarassed',\n",
       " '09041940223',\n",
       " 'fave',\n",
       " 'temp',\n",
       " 'usmle',\n",
       " 'bone',\n",
       " 'shinco',\n",
       " '6pm',\n",
       " 'promotion',\n",
       " 'appointment',\n",
       " 'cheque',\n",
       " 'iwana',\n",
       " 'finishes',\n",
       " 'mango',\n",
       " 'walking',\n",
       " 'leona',\n",
       " 'msging',\n",
       " 'nigh',\n",
       " 'rub',\n",
       " 'black',\n",
       " 'dsn',\n",
       " '33',\n",
       " 'hearing',\n",
       " 'sp',\n",
       " 'veggie',\n",
       " 'kept',\n",
       " 'teaching',\n",
       " 'getting',\n",
       " 'weirdy',\n",
       " 'skye',\n",
       " 'cuddling',\n",
       " 'unhappiness',\n",
       " 'belive',\n",
       " '09065989180',\n",
       " 'ure',\n",
       " 'irene',\n",
       " 'kid',\n",
       " 'motive',\n",
       " 'lov',\n",
       " 'ahold',\n",
       " 'skint',\n",
       " 'necessarily',\n",
       " 'bottom',\n",
       " '09050005321',\n",
       " 'regular',\n",
       " 'newquay',\n",
       " 'apo',\n",
       " 'usps',\n",
       " 'inr',\n",
       " 'deltomorrow',\n",
       " 'crazyin',\n",
       " 'qet',\n",
       " 'stranger',\n",
       " 'bold',\n",
       " 'pocked',\n",
       " 'place',\n",
       " 'doctor',\n",
       " 'med',\n",
       " 'rough',\n",
       " 'mathematics',\n",
       " 'evaporated',\n",
       " 'revision',\n",
       " 'admit',\n",
       " 'l8tr',\n",
       " 'possessiveness',\n",
       " 'dating',\n",
       " 'sleeps',\n",
       " 'don',\n",
       " 'computational',\n",
       " 'ability',\n",
       " 'tb',\n",
       " 'onion',\n",
       " 'evone',\n",
       " 'matrix3',\n",
       " 'xin',\n",
       " 'permissions',\n",
       " 'leo',\n",
       " 'goodmate',\n",
       " 'loss',\n",
       " 'tis',\n",
       " 'arcade',\n",
       " '50s',\n",
       " 'against',\n",
       " 'kickoff',\n",
       " 'cheat',\n",
       " 'arsenal',\n",
       " 'mobcudb',\n",
       " 'alwa',\n",
       " 'orc',\n",
       " 'petrol',\n",
       " 'reserves',\n",
       " 'forum',\n",
       " 'afew',\n",
       " 'physics',\n",
       " '6ph',\n",
       " 'exact',\n",
       " 'bajarangabali',\n",
       " 'cream',\n",
       " 'php',\n",
       " 'lim',\n",
       " '83738',\n",
       " '89545',\n",
       " 'superior',\n",
       " 'remembrs',\n",
       " 'aight',\n",
       " 'plus',\n",
       " 'sunday',\n",
       " 'madoke',\n",
       " 'continue',\n",
       " 'sweet',\n",
       " 'curry',\n",
       " 'supreme',\n",
       " 'missunderstding',\n",
       " 'o2',\n",
       " 'less',\n",
       " 'creativity',\n",
       " 'nvm',\n",
       " 'jas',\n",
       " 'wil',\n",
       " 'esaplanade',\n",
       " 'sue',\n",
       " 'vibrator',\n",
       " 'wan',\n",
       " 'k61',\n",
       " 'then',\n",
       " 'group',\n",
       " 'part',\n",
       " 'stop2stop',\n",
       " 'rimac',\n",
       " '4d',\n",
       " 'wud',\n",
       " 'ge',\n",
       " 'usc',\n",
       " 'ay',\n",
       " 'change',\n",
       " '150pw',\n",
       " 'experiment',\n",
       " 'hogidhe',\n",
       " 'services',\n",
       " 'equally',\n",
       " 'picked',\n",
       " 'appointments',\n",
       " '645',\n",
       " 'gudni8',\n",
       " 'jealous',\n",
       " 'thx',\n",
       " 'specs',\n",
       " '08715705022',\n",
       " 'greatest',\n",
       " 'odalebeku',\n",
       " 'vic',\n",
       " 'dis',\n",
       " 'subtoitles',\n",
       " 'stayin',\n",
       " '06',\n",
       " 'classes',\n",
       " 'yifeng',\n",
       " 'cc',\n",
       " 'braindance',\n",
       " 'twelve',\n",
       " 'openin',\n",
       " 'fights',\n",
       " 'noon',\n",
       " 'oscar',\n",
       " 'trips',\n",
       " '08718711108',\n",
       " 'theres',\n",
       " 'forced',\n",
       " 'walkin',\n",
       " 'unusual',\n",
       " 'linux',\n",
       " 'myspace',\n",
       " 'east',\n",
       " 'abiola',\n",
       " 'ms',\n",
       " 'matured',\n",
       " 'sum',\n",
       " 'fated',\n",
       " 'never',\n",
       " 'fulfil',\n",
       " 'torrents',\n",
       " '45pm',\n",
       " '100p',\n",
       " 'inform',\n",
       " 'gifts',\n",
       " 'insurance',\n",
       " 'complaining',\n",
       " 'nigeria',\n",
       " 'stands',\n",
       " 'kidz',\n",
       " 'chuckin',\n",
       " 'girlie',\n",
       " 'befor',\n",
       " '08719899230',\n",
       " 'realize',\n",
       " 'hg',\n",
       " 'asking',\n",
       " 'friendship',\n",
       " 'inviting',\n",
       " 'own',\n",
       " 'deduct',\n",
       " 'pharmacy',\n",
       " 'sc',\n",
       " 'nothin',\n",
       " 'shot',\n",
       " '5249',\n",
       " 'pathaya',\n",
       " 'deluxe',\n",
       " 'camcorder',\n",
       " 'poyyarikatur',\n",
       " 'setting',\n",
       " 'appear',\n",
       " 'meaningless',\n",
       " 'shijas',\n",
       " 'alex',\n",
       " 'gudnyt',\n",
       " 'bridal',\n",
       " 'sun',\n",
       " 'mumtaz',\n",
       " '9ja',\n",
       " 'cliff',\n",
       " 'information',\n",
       " 'mayb',\n",
       " 'diwali',\n",
       " '18',\n",
       " '3510i',\n",
       " 'excused',\n",
       " '2nd',\n",
       " 'sentiment',\n",
       " 'werebored',\n",
       " 'thrown',\n",
       " 'talks',\n",
       " 'beware',\n",
       " 'elaya',\n",
       " 'ym',\n",
       " 'cutefrnd',\n",
       " 'redeemable',\n",
       " '3d',\n",
       " 'breakin',\n",
       " 'mobs',\n",
       " 'wonderful',\n",
       " 'garments',\n",
       " 'rental',\n",
       " 'miss',\n",
       " 'scammers',\n",
       " 'sic',\n",
       " 'no',\n",
       " 'sh',\n",
       " 'delivery',\n",
       " 'max10mins',\n",
       " 'kent',\n",
       " 'unlimited',\n",
       " 'wuldnt',\n",
       " 'saying',\n",
       " 'emc1',\n",
       " 'bcums',\n",
       " '32',\n",
       " 'problem',\n",
       " 'cleared',\n",
       " 'weed',\n",
       " 'earliest',\n",
       " 'care',\n",
       " 'showers',\n",
       " 'infernal',\n",
       " 'bigger',\n",
       " 'heron',\n",
       " 'live',\n",
       " 'lennon',\n",
       " 'thanx4',\n",
       " 'today',\n",
       " '09061701939',\n",
       " 'millions',\n",
       " 'barkleys',\n",
       " 'insha',\n",
       " 'carefully',\n",
       " 'painting',\n",
       " 'xxxxxx',\n",
       " 'iraq',\n",
       " '87077',\n",
       " 'chrgd',\n",
       " 'bookedthe',\n",
       " 'headset',\n",
       " '09066382422',\n",
       " 'e14',\n",
       " 'bx526',\n",
       " 'infront',\n",
       " 'height',\n",
       " 'gprs',\n",
       " 'position',\n",
       " 'fifa',\n",
       " 'yeesh',\n",
       " 'loo',\n",
       " 'lick',\n",
       " '09050280520',\n",
       " 'special',\n",
       " 'hanks',\n",
       " 'raise',\n",
       " 'management',\n",
       " 'convey',\n",
       " 'places',\n",
       " 'wants',\n",
       " 'myparents',\n",
       " '82324',\n",
       " 'hme',\n",
       " 'granite',\n",
       " 'upgrdcentre',\n",
       " 'poured',\n",
       " 'harry',\n",
       " '86021',\n",
       " 'thepub',\n",
       " 'greet',\n",
       " 'mecause',\n",
       " 'tomorro',\n",
       " 'randy',\n",
       " 'waaaat',\n",
       " 'boys',\n",
       " '08712103738',\n",
       " 'surname',\n",
       " 'lousy',\n",
       " '545',\n",
       " 'mood',\n",
       " 'cs',\n",
       " 'bc',\n",
       " 'birds',\n",
       " 'percentages',\n",
       " 'woods',\n",
       " '008704050406',\n",
       " 'taj',\n",
       " 'dismissial',\n",
       " 'hl',\n",
       " 'hopeful',\n",
       " 'best',\n",
       " 'specific',\n",
       " 'deficient',\n",
       " 'notified',\n",
       " 'simply',\n",
       " 'thedailydraw',\n",
       " 'texts',\n",
       " 'moji',\n",
       " 'incomm',\n",
       " 'weaknesses',\n",
       " 'honeymoon',\n",
       " 'minmoremobsemspobox45po139wa',\n",
       " '09063440451',\n",
       " 'yelling',\n",
       " 'la',\n",
       " 'shit',\n",
       " 'surya',\n",
       " 'closeby',\n",
       " '448712404000',\n",
       " '2007',\n",
       " 'july',\n",
       " 'adewale',\n",
       " '60',\n",
       " 'ordinator',\n",
       " '30pp',\n",
       " 'mail',\n",
       " 'creative',\n",
       " 'stone',\n",
       " 'birthday',\n",
       " 'erm',\n",
       " 'explicitly',\n",
       " '5226',\n",
       " 'panties',\n",
       " 'needed',\n",
       " '08714712388',\n",
       " 'cricket',\n",
       " 'thgt',\n",
       " 'punish',\n",
       " 'only',\n",
       " 'stagwood',\n",
       " 'yam',\n",
       " '220cm2',\n",
       " 'floating',\n",
       " 'shell',\n",
       " 'cappuccino',\n",
       " 'chinnu',\n",
       " 'cttergg',\n",
       " 'want2come',\n",
       " 'cutie',\n",
       " 'wikipedia',\n",
       " '430',\n",
       " 'ak',\n",
       " 'dying',\n",
       " 'iwas',\n",
       " 'what',\n",
       " '09058094599',\n",
       " 'spare',\n",
       " 'coco',\n",
       " 'rwm',\n",
       " '66',\n",
       " 'knows',\n",
       " 'mint',\n",
       " 'accidant',\n",
       " 'it',\n",
       " 'pimples',\n",
       " 'converted',\n",
       " 'burial',\n",
       " 'baaaaaaaabe',\n",
       " 'stil',\n",
       " 'studying',\n",
       " 'mag',\n",
       " 'irritating',\n",
       " 'payed',\n",
       " 'thout',\n",
       " 'purity',\n",
       " 'british',\n",
       " 'titles',\n",
       " 'leonardo',\n",
       " 'phone',\n",
       " 'talents',\n",
       " 'oooooh',\n",
       " '09061743386',\n",
       " 'banneduk',\n",
       " 'wheellock',\n",
       " 'asssssholeeee',\n",
       " 'boyf',\n",
       " 'terrorist',\n",
       " 'shirts',\n",
       " '30apr',\n",
       " '2c',\n",
       " 'maaaan',\n",
       " 'skillgame',\n",
       " 'suman',\n",
       " 'aiya',\n",
       " 'olol',\n",
       " 'comedy',\n",
       " '08712460324',\n",
       " 'sight',\n",
       " 'hidden',\n",
       " 'porridge',\n",
       " 'answering',\n",
       " 'xxx',\n",
       " 'yalrigu',\n",
       " 'lac',\n",
       " 'software',\n",
       " 'traffic',\n",
       " '09061749602',\n",
       " 'gr8',\n",
       " 'dream',\n",
       " 'samus',\n",
       " 'view',\n",
       " 'after',\n",
       " 'canlove',\n",
       " 'squatting',\n",
       " '6031',\n",
       " 'lil',\n",
       " 'plumbers',\n",
       " 'bhayandar',\n",
       " 'detail',\n",
       " '08702840625',\n",
       " 'fever',\n",
       " 'fundamentals',\n",
       " 'number',\n",
       " '09099726481',\n",
       " 'tampa',\n",
       " 'rum',\n",
       " 'reference',\n",
       " 'announcement',\n",
       " '0871750',\n",
       " 'days',\n",
       " 'waiting',\n",
       " 'tmr',\n",
       " 'accounting',\n",
       " 'awarded',\n",
       " '08712317606',\n",
       " 'mojibiola',\n",
       " 'asks',\n",
       " 'wrecked',\n",
       " 'hear',\n",
       " 'dled',\n",
       " '44345',\n",
       " 'cash',\n",
       " 'gv',\n",
       " 'ouch',\n",
       " 'neway',\n",
       " 'tahan',\n",
       " 'curious',\n",
       " 'pros',\n",
       " 'pre',\n",
       " 'shorter',\n",
       " 'attraction',\n",
       " 'urgoin',\n",
       " 'my',\n",
       " 'appt',\n",
       " 'value',\n",
       " 'ola',\n",
       " 'ass',\n",
       " 'exhaust',\n",
       " 'waz',\n",
       " 'nok',\n",
       " '7876150ppm',\n",
       " 'recycling',\n",
       " 'm221bp',\n",
       " '8wp',\n",
       " 'thot',\n",
       " 'velachery',\n",
       " 'massage',\n",
       " 'near',\n",
       " 'psychologist',\n",
       " 'complementary',\n",
       " 'workand',\n",
       " 'spun',\n",
       " 'ratio',\n",
       " 'bless',\n",
       " '14',\n",
       " 'imposed',\n",
       " '0789xxxxxxx',\n",
       " 'hoo',\n",
       " 'regalportfolio',\n",
       " 'interfued',\n",
       " 'raviyog',\n",
       " '08718727868',\n",
       " 'ad',\n",
       " 'cann',\n",
       " 'market',\n",
       " 'extra',\n",
       " 'indicate',\n",
       " 'graphics',\n",
       " 'summon',\n",
       " 'wat',\n",
       " 'yorge',\n",
       " 'join',\n",
       " 'determined',\n",
       " 'choices',\n",
       " 'splleing',\n",
       " 'w1j',\n",
       " 'haunt',\n",
       " '1pm',\n",
       " 'cal',\n",
       " 'cha',\n",
       " '08719181513',\n",
       " 'retrieve',\n",
       " 'smoked',\n",
       " 'trainners',\n",
       " '630',\n",
       " 'authorise',\n",
       " 'irritated',\n",
       " 'lotr',\n",
       " '80160',\n",
       " 'pull',\n",
       " 'icic',\n",
       " 'refreshed',\n",
       " 'saeed',\n",
       " 'borin',\n",
       " '087018728737',\n",
       " 'breathe',\n",
       " 'tolerance',\n",
       " 'whatsup',\n",
       " 'watch',\n",
       " 'rcv',\n",
       " 'beautiful',\n",
       " 'gay',\n",
       " '8077',\n",
       " 'role',\n",
       " 'ovulation',\n",
       " 'ave',\n",
       " 'doug',\n",
       " 'till',\n",
       " 'vomiting',\n",
       " 'cardiff',\n",
       " 'jeremiah',\n",
       " 'polo',\n",
       " 'assume',\n",
       " 'twenty',\n",
       " 'macho',\n",
       " 'landlineonly',\n",
       " '2day',\n",
       " 'locaxx',\n",
       " 'maid',\n",
       " 'ruin',\n",
       " 'plum',\n",
       " 'may',\n",
       " 'time',\n",
       " 'legal',\n",
       " 'age23',\n",
       " 'msg',\n",
       " 'yan',\n",
       " 'pax',\n",
       " 'ignoring',\n",
       " 'shant',\n",
       " 'assumed',\n",
       " 'dancing',\n",
       " 'asus',\n",
       " 'cl',\n",
       " 'blame',\n",
       " '08715500022',\n",
       " '88222',\n",
       " '100txt',\n",
       " 'waking',\n",
       " 'teams',\n",
       " 'box334sk38ch',\n",
       " 'overemphasise',\n",
       " 'messy',\n",
       " 'sam',\n",
       " 'box245c2150pm',\n",
       " 'funs',\n",
       " 'villa',\n",
       " 'ldn',\n",
       " '2waxsto',\n",
       " 'tor',\n",
       " 'bcoz',\n",
       " 'establish',\n",
       " 'teacher',\n",
       " 'vaguely',\n",
       " 'shuhui',\n",
       " 'resolution',\n",
       " 'either',\n",
       " '08717111821',\n",
       " 'with',\n",
       " 'engaged',\n",
       " 'prepaid',\n",
       " 'den',\n",
       " 'inmind',\n",
       " 'tagged',\n",
       " 'domain',\n",
       " 'thurs',\n",
       " 'invaders',\n",
       " 'turns',\n",
       " 'owns',\n",
       " 'really',\n",
       " 'nd',\n",
       " 'rcvd',\n",
       " 'd',\n",
       " 'fixed',\n",
       " 'asia',\n",
       " '09065069154',\n",
       " '09058094454',\n",
       " 'velly',\n",
       " 'cw25wx',\n",
       " 'pobox114',\n",
       " 'aboutas',\n",
       " 'bsnl',\n",
       " 'springs',\n",
       " 'bash',\n",
       " 'castor',\n",
       " 'turn',\n",
       " 'mandy',\n",
       " 'minuts',\n",
       " 'meaningful',\n",
       " '1yf',\n",
       " 'isn',\n",
       " 'appeal',\n",
       " 'wthout',\n",
       " 'fear',\n",
       " 'settings',\n",
       " 'conform',\n",
       " 'dine',\n",
       " 'nalli',\n",
       " '8027',\n",
       " 'ft',\n",
       " 'mailbox',\n",
       " 'back',\n",
       " 'recd',\n",
       " 'considering',\n",
       " 'tookplace',\n",
       " 'asthere',\n",
       " 'taxt',\n",
       " 'badrith',\n",
       " 'merry',\n",
       " 'brown',\n",
       " 'gentleman',\n",
       " 'voice',\n",
       " 'memory',\n",
       " 'dec',\n",
       " 'lt',\n",
       " 'cute',\n",
       " 'praps',\n",
       " 'normally',\n",
       " 'making',\n",
       " 'hostile',\n",
       " 'ello',\n",
       " 'mad',\n",
       " 'humans',\n",
       " 'flute',\n",
       " 'relax',\n",
       " 'hundreds',\n",
       " 'courageous',\n",
       " 'itz',\n",
       " 'creepy',\n",
       " 'unable',\n",
       " 'mess',\n",
       " 'oso',\n",
       " 'somewheresomeone',\n",
       " 'lucy',\n",
       " 'there',\n",
       " 'lab',\n",
       " 'mwahs',\n",
       " 'patty',\n",
       " '0870753331018',\n",
       " 'toxic',\n",
       " 'conducts',\n",
       " 'tom',\n",
       " 'buff',\n",
       " '85023',\n",
       " 'rules',\n",
       " 'planet',\n",
       " 'mei',\n",
       " 'watchin',\n",
       " 'claims',\n",
       " 'tscs',\n",
       " 'tomeandsaid',\n",
       " 'cyclists',\n",
       " 'said',\n",
       " 'birthdate',\n",
       " 'kitty',\n",
       " 'shopping',\n",
       " 'costs',\n",
       " 'point',\n",
       " 'harder',\n",
       " 'desert',\n",
       " 'uptown',\n",
       " 'clocks',\n",
       " 'ben',\n",
       " 'latr',\n",
       " 'lazy',\n",
       " 'hands',\n",
       " 'prepared',\n",
       " 'requires',\n",
       " 'annoyin',\n",
       " 'laughed',\n",
       " 'argument',\n",
       " 'pobox1',\n",
       " '09099726553',\n",
       " 'member',\n",
       " 'especially',\n",
       " 'm26',\n",
       " 'ones',\n",
       " 'kavalan',\n",
       " 'job',\n",
       " 'rudi',\n",
       " 'spiffing',\n",
       " 'reboot',\n",
       " 'secured',\n",
       " 'plural',\n",
       " 'innocent',\n",
       " 'manege',\n",
       " 'mad2',\n",
       " '447797706009',\n",
       " 'actor',\n",
       " '82050',\n",
       " 'shampain',\n",
       " 'park',\n",
       " 'witin',\n",
       " 'recognises',\n",
       " 'effects',\n",
       " 'ag',\n",
       " 'bpo',\n",
       " 'star',\n",
       " '89034',\n",
       " 'xxxxxxxx',\n",
       " 'hill',\n",
       " 'psychiatrist',\n",
       " '08081560665',\n",
       " 'telephonic',\n",
       " 'lifebook',\n",
       " 'phb1',\n",
       " 'tomarrow',\n",
       " 'hahaha',\n",
       " 'unni',\n",
       " 'cakes',\n",
       " 'vatian',\n",
       " 'september',\n",
       " 'abel',\n",
       " 'offers',\n",
       " 'nigro',\n",
       " 'needs',\n",
       " 'adult',\n",
       " 'webpage',\n",
       " 'kl341',\n",
       " 'ansr',\n",
       " 'closes',\n",
       " 'downloads',\n",
       " 'lay',\n",
       " 'administrator',\n",
       " 'occupy',\n",
       " 'agalla',\n",
       " 'inde',\n",
       " 'hmv',\n",
       " 'ended',\n",
       " 'expect',\n",
       " 'responding',\n",
       " 'uncles',\n",
       " 'xafter',\n",
       " 'hdd',\n",
       " 'frnt',\n",
       " 'news',\n",
       " 'fault',\n",
       " 'sonetimes',\n",
       " 'reflection',\n",
       " '09050000878',\n",
       " 'cashto',\n",
       " 'im',\n",
       " 'pin',\n",
       " 'ros',\n",
       " '4info',\n",
       " 'ppl',\n",
       " 'companies',\n",
       " 'michael',\n",
       " 'wet',\n",
       " 'first',\n",
       " 'straight',\n",
       " 'sells',\n",
       " 'breather',\n",
       " 'r',\n",
       " 'melody',\n",
       " ...]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = []\n",
    "\n",
    "def list_words(x):\n",
    "    for word in x:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "training_set[\"SMS\"] = training_set[\"SMS\"].str.split()\n",
    "training_set[\"SMS\"].apply(list_words)\n",
    "\n",
    "vocabulary = list(set(vocabulary))\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Transformation\n",
    "\n",
    "Now we are going to use the vocabulary list to transform out dataset:\n",
    "\n",
    "![Image of Yaktocat](https://dq-content.s3.amazonaws.com/433/cpgp_dataset_3.png)\n",
    "\n",
    "\n",
    "Every column, except \"Label\", will represent the number of times some word is in each message.\n",
    "For example, in the first message you can see it has the words \"secret\" and \"prize\" repeated 2 times and the \"claim\" and \"now\" words repeated one time.\n",
    "\n",
    "For the division of the columns, first we need to create a dictionary, with the unique words being the index and a list representing the number of times a word has repeated in the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>brains</th>\n",
       "      <th>mahal</th>\n",
       "      <th>claimcode</th>\n",
       "      <th>unconsciously</th>\n",
       "      <th>accordin</th>\n",
       "      <th>310303</th>\n",
       "      <th>ed</th>\n",
       "      <th>bunkers</th>\n",
       "      <th>...</th>\n",
       "      <th>drink</th>\n",
       "      <th>jos</th>\n",
       "      <th>le</th>\n",
       "      <th>sorts</th>\n",
       "      <th>panasonic</th>\n",
       "      <th>chk</th>\n",
       "      <th>cttargg</th>\n",
       "      <th>intend</th>\n",
       "      <th>helpline</th>\n",
       "      <th>5wb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4453</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, ve, told, you, everything, will, stop, jus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4454</td>\n",
       "      <td>ham</td>\n",
       "      <td>[or, i, guess, lt, gt, min]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4455</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, m, home, ard, wat, time, will, u, reach]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4456</td>\n",
       "      <td>ham</td>\n",
       "      <td>[storming, msg, wen, u, lift, d, phne, u, say,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4457</td>\n",
       "      <td>ham</td>\n",
       "      <td>[if, you, want, to, mapquest, it, or, somethin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4458 rows × 7815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS  brains  mahal  \\\n",
       "0      ham  [go, until, jurong, point, crazy, available, o...       0      0   \n",
       "1      ham                     [ok, lar, joking, wif, u, oni]       0      0   \n",
       "2     spam  [free, entry, in, 2, a, wkly, comp, to, win, f...       0      0   \n",
       "3      ham  [u, dun, say, so, early, hor, u, c, already, t...       0      0   \n",
       "4      ham  [nah, i, don, t, think, he, goes, to, usf, he,...       0      0   \n",
       "...    ...                                                ...     ...    ...   \n",
       "4453   ham  [i, ve, told, you, everything, will, stop, jus...       0      0   \n",
       "4454   ham                        [or, i, guess, lt, gt, min]       0      0   \n",
       "4455   ham       [i, m, home, ard, wat, time, will, u, reach]       0      0   \n",
       "4456   ham  [storming, msg, wen, u, lift, d, phne, u, say,...       0      0   \n",
       "4457   ham  [if, you, want, to, mapquest, it, or, somethin...       0      0   \n",
       "\n",
       "      claimcode  unconsciously  accordin  310303  ed  bunkers  ...  drink  \\\n",
       "0             0              0         0       0   0        0  ...      0   \n",
       "1             0              0         0       0   0        0  ...      0   \n",
       "2             0              0         0       0   0        0  ...      0   \n",
       "3             0              0         0       0   0        0  ...      0   \n",
       "4             0              0         0       0   0        0  ...      0   \n",
       "...         ...            ...       ...     ...  ..      ...  ...    ...   \n",
       "4453          0              0         0       0   0        0  ...      0   \n",
       "4454          0              0         0       0   0        0  ...      0   \n",
       "4455          0              0         0       0   0        0  ...      0   \n",
       "4456          0              0         0       0   0        0  ...      0   \n",
       "4457          0              0         0       0   0        0  ...      0   \n",
       "\n",
       "      jos  le  sorts  panasonic  chk  cttargg  intend  helpline  5wb  \n",
       "0       0   0      0          0    0        0       0         0    0  \n",
       "1       0   0      0          0    0        0       0         0    0  \n",
       "2       0   0      0          0    0        0       0         0    0  \n",
       "3       0   0      0          0    0        0       0         0    0  \n",
       "4       0   0      0          0    0        0       0         0    0  \n",
       "...   ...  ..    ...        ...  ...      ...     ...       ...  ...  \n",
       "4453    0   0      0          0    0        0       0         0    0  \n",
       "4454    0   0      0          0    0        0       0         0    0  \n",
       "4455    0   0      0          0    0        0       0         0    0  \n",
       "4456    0   0      0          0    0        0       0         0    0  \n",
       "4457    0   0      0          0    0        0       0         0    0  \n",
       "\n",
       "[4458 rows x 7815 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "\n",
    "words_df = pd.DataFrame(word_counts_per_sms)\n",
    "training_set_clean = pd.concat([training_set, words_df], axis=1)\n",
    "training_set_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Algorithm\n",
    "\n",
    "Now we are going to build the Naive Bayes algorithm using the following formula:\n",
    "\n",
    "![title](img/bayes_formula.jpg)\n",
    "\n",
    "To calculate P(wi|Spam) and P(wi|Ham) we need to use the following formulas:\n",
    "\n",
    "![title](img/prob_form.jpg)\n",
    "\n",
    "We will apply Laplace smoothing α to the numerator and denominator so that when one of the probabilities is 0 it doesn't mess up the equation.\n",
    "\n",
    "First we are going to calculate the constant values:\n",
    "- P(Spam)\n",
    "- P(Ham)\n",
    "- N spam\n",
    "- N ham\n",
    "- N vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(Ham)\n",
    "ham_p = training_set_clean.Label.value_counts(normalize=True).values.tolist()[0]\n",
    "#P(Spam)\n",
    "spam_p = training_set_clean.Label.value_counts(normalize=True).values.tolist()[1]\n",
    "\n",
    "#N ham\n",
    "n_ham = training_set_clean[training_set_clean[\"Label\"] == \"ham\"][\"SMS\"].apply(len).sum()\n",
    "#N sp\n",
    "n_spam = training_set_clean[training_set_clean[\"Label\"] == \"spam\"][\"SMS\"].apply(len).sum()\n",
    "#N vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "# α\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Parameters\n",
    "\n",
    "Now we are going to calculate the following probabilities:\n",
    "\n",
    "![title](img/prob_form.jpg)\n",
    "\n",
    "For each word in the spam or non spam-message, calculate the probability of them appearing in a spam o a non-spam message. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create two dictionaries where the words probabilities are going to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dic = {word: 0 for word in vocabulary}\n",
    "ham_dic = {word: 0 for word in vocabulary}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the dataframe in two dataframes by spam and non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_messages = training_set_clean[training_set_clean.Label == \"ham\"]\n",
    "spam_messages = training_set_clean[training_set_clean.Label == \"spam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate the probability that each word of the dictionary appears in a spam or non-spam message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in vocabulary:\n",
    "    \n",
    "    #We calculate the probability of the word given that \n",
    "    n_word_spam = spam_messages[i].sum()\n",
    "    n_word_ham = ham_messages[i].sum()\n",
    "    \n",
    "    spam_dic[i] = (n_word_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    ham_dic[i] = (n_word_ham + alpha) / (n_ham + alpha*n_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the classify function\n",
    "\n",
    "Now we are going to create a function that classifies a message as Spam o Non-Spam. The steps are going to be:\n",
    "\n",
    "1. Clean the message.\n",
    "2. Multiply probabilities and determine the probability of being a Spam or Non-Spam message using Naive Bayes algorithm.\n",
    "3. Print results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    #Message Cleaning:\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    #Defining the probabilities\n",
    "    p_spam_given_message = spam_p\n",
    "    p_ham_given_message = ham_p\n",
    "    \n",
    "    #Multiplying probabilities\n",
    "    for word in message:\n",
    "        if word in spam_dic:\n",
    "            p_spam_given_message *= spam_dic[word]\n",
    "        \n",
    "        if word in ham_dic:\n",
    "            p_ham_given_message *= ham_dic[word]\n",
    "    \n",
    "    #Print percentages\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    #Determine if the message is Spam or Non-Spam\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.1946675407236375e-25\n",
      "P(Ham|message): 2.538390052402955e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 6.307218028475593e-25\n",
      "P(Ham|message): 4.417049039139304e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filter Accuracy\n",
    "\n",
    "We are going to measure the accuracy of the spam filter using the test dataset. The accuracy metric will be calculated by dividing the number of correctly classified messages by the total number of classified messsages.\n",
    "\n",
    "First we will create a function that will be similar to the classify function, but it will return the labels instead of printing them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = spam_p\n",
    "    p_ham_given_message = ham_p\n",
    "\n",
    "    for word in message:\n",
    "        if word in spam_dic:\n",
    "            p_spam_given_message *= spam_dic[word]\n",
    "        \n",
    "        if word in ham_dic:\n",
    "            p_ham_given_message *= ham_dic[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the function to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>aight should i just plan to come up later toni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>die    i accidentally deleted e msg i suppose ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>welcome to uk mobile date this msg is free giv...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>this is wishing you a great day  moji told me ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>thanks again for your reply today  when is ur ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham  aight should i just plan to come up later toni...       ham\n",
       "1   ham  die    i accidentally deleted e msg i suppose ...       ham\n",
       "2  spam  welcome to uk mobile date this msg is free giv...      spam\n",
       "3   ham  this is wishing you a great day  moji told me ...       ham\n",
       "4   ham  thanks again for your reply today  when is ur ...       ham"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(test_set)\n",
    "\n",
    "correct_list = test_set[\"predicted\"] == test_set[\"Label\"]\n",
    "correct = correct_list.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856373429084381"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = correct / total\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Using the Spam filter in the test dataset, we can see that the model has an accuracy of 98.56%. We meet the objective of having a model with higher precision than 80%. The multinomial Naive Bayes algorithm is very effective at classification problems. This model could be adapted for other problems like detecting false news.\n",
    "\n",
    "There is still room for improvement and make this spam filter more precise. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
